{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the jet tagging dataset from Open ML (run this only once, this can take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_openml('hls4ml_lhc_jets_hlf')\n",
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's print some information about the dataset\n",
    "Print the feature names and the dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zlogz', 'c1_b0_mmdt', 'c1_b1_mmdt', 'c1_b2_mmdt', 'c2_b1_mmdt', 'c2_b2_mmdt', 'd2_b1_mmdt', 'd2_b2_mmdt', 'd2_a1_b1_mmdt', 'd2_a1_b2_mmdt', 'm2_b1_mmdt', 'm2_b2_mmdt', 'n2_b1_mmdt', 'n2_b2_mmdt', 'mass_mmdt', 'multiplicity']\n",
      "(830000, 16) (830000,)\n",
      "[[-2.93512535e+00  3.83155316e-01  5.12587558e-03  8.42466834e-05\n",
      "   9.06995591e-03  1.78931368e-04  1.76944518e+00  2.12389827e+00\n",
      "   1.76944518e+00  3.08185428e-01  1.35686919e-01  8.32780078e-02\n",
      "   4.12136108e-01  2.99057871e-01  8.92688179e+00  7.50000000e+01]\n",
      " [-1.92733514e+00  2.70698756e-01  1.58540264e-03  1.13709866e-05\n",
      "   3.23237223e-03  2.91449633e-05  2.03883362e+00  2.56309891e+00\n",
      "   2.03883362e+00  2.11886495e-01  6.37285784e-02  3.63104008e-02\n",
      "   3.10216516e-01  2.26661310e-01  3.88651156e+00  3.10000000e+01]\n",
      " [-3.11214662e+00  4.58171129e-01  9.79138538e-02  2.85884105e-02\n",
      "   1.24277540e-01  3.84868123e-02  1.26925385e+00  1.34623826e+00\n",
      "   1.26925385e+00  2.46488109e-01  1.15635969e-01  7.90941268e-02\n",
      "   3.57558519e-01  2.89219588e-01  1.62144669e+02  6.10000000e+01]\n",
      " [-2.66651511e+00  4.37067598e-01  4.91220504e-02  7.97829404e-03\n",
      "   4.74766865e-02  4.80184611e-03  9.66504514e-01  6.01863742e-01\n",
      "   9.66504514e-01  1.60756409e-01  8.21964443e-02  3.33105028e-02\n",
      "   2.38870576e-01  9.45160612e-02  9.12589340e+01  3.90000000e+01]\n",
      " [-2.48484278e+00  4.28981334e-01  4.17859703e-02  6.10950543e-03\n",
      "   2.30659451e-02  1.12305430e-03  5.52002132e-01  1.83820814e-01\n",
      "   5.52002132e-01  8.43379796e-02  4.80063371e-02  1.44504104e-02\n",
      "   1.41905606e-01  3.66654508e-02  7.97257767e+01  3.50000000e+01]]\n",
      "['g' 'w' 't' 'z' 'w' 'w' 't' 'g' 'z' 'g']\n"
     ]
    }
   ],
   "source": [
    "print(data['feature_names'])\n",
    "print(X.shape, y.shape)\n",
    "print(X[:5])\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you saw above, the `y` target is an array of strings, e.g. \\['g', 'w',...\\] etc.\n",
    "We need to make this a \"One Hot\" encoding for the training.\n",
    "Then, split the dataset into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['g' 'q' 't' 'w' 'z']\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(y)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 2 4 3 3 2 0 4 0]\n"
     ]
    }
   ],
   "source": [
    "yl = le.transform(y)\n",
    "print(yl[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "yc = to_categorical(yl, len(le.classes_))\n",
    "print(yc[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, yc, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import setGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  4044  100  4044    0     0  12882      0 --:--:-- --:--:-- --:--:-- 12920\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/fastmachinelearning/hls4ml-tutorial/master/callbacks.py > callbacks.py\n",
    "#!curl https://raw.githubusercontent.com/fastmachinelearning/hls4ml-tutorial/master/plotting.py > plotting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def History(label, h):\n",
    "    plt.plot( h.history['loss'], label ='Training Loss: {}'.format(label))\n",
    "    plt.plot( h.history['val_loss'], label = 'Validation Loss: {}'.format(label))\n",
    "    plt.plot( h.history['accuracy'], label = 'Training Accuracy: {}'.format(label))\n",
    "    plt.plot( h.history['val_accuracy'], label = 'Validation Accuracy: {}'.format(label))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(m):\n",
    "    pred = m.predict( X_test)\n",
    "    a = accuracy_score(np.argmax(y_test, axis=1), np.argmax(pred, axis=1))\n",
    "    print(\"Accuracy: {}: {}\".format(m.name, a))\n",
    "    return pred, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a simple dense model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 3 hidden layers with 64, then 32, then 32 neurons. Each layer will use `relu` activation.\n",
    "Add an output layer with 5 neurons (one for each class), then finish with Softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense, Activation, BatchNormalization, Conv1D, Dropout, Reshape, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from callbacks import all_callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(shape=(16,))\n",
    "d = Dense(32, name='fc1', activation='relu')(i)\n",
    "d = Dense(64, name='fc2', activation='relu')(d)\n",
    "d = Dense(64, name='fc3', activation='relu')(d)\n",
    "o = Dense(len(le.classes_), activation='softmax', name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001))(d)\n",
    "model_1 = Model(inputs=i, outputs=o, name='model_DNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_DNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_59 (InputLayer)        [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 7,141\n",
      "Trainable params: 7,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We'll use Adam optimizer with categorical crossentropy loss.\n",
    "The model isn't very complex, so this should just take a few minutes even on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "model_1.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 1.7479 - accuracy: 0.3812 - val_loss: 1.3244 - val_accuracy: 0.4168\n",
      "Epoch 2/2\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 1.2756 - accuracy: 0.4651 - val_loss: 1.2247 - val_accuracy: 0.5470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f89083004e0>"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train_val, y_train_val, batch_size=1024,\n",
    "              epochs=2, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: model_DNN: 0.5467349397590362\n"
     ]
    }
   ],
   "source": [
    "y_predict_1, a_1 = Accuracy(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(shape=(16,))\n",
    "r = Reshape((16,1))(i)\n",
    "c = Conv1D(16, 3, name='cv1', activation='relu')(r)\n",
    "c = Conv1D(16, 3, name='cv2', activation='relu')(c)\n",
    "c = Conv1D(16, 3, name='cv3', activation='relu')(c)\n",
    "f = Flatten()(c)\n",
    "o = Dense(len(le.classes_), activation='softmax', name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001))(f)\n",
    "model_2 = Model(inputs=i, outputs=o, name='model_CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_60 (InputLayer)        [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "reshape_32 (Reshape)         (None, 16, 1)             0         \n",
      "_________________________________________________________________\n",
      "cv1 (Conv1D)                 (None, 14, 16)            64        \n",
      "_________________________________________________________________\n",
      "cv2 (Conv1D)                 (None, 12, 16)            784       \n",
      "_________________________________________________________________\n",
      "cv3 (Conv1D)                 (None, 10, 16)            784       \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 805       \n",
      "=================================================================\n",
      "Total params: 2,437\n",
      "Trainable params: 2,437\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We'll use Adam optimizer with categorical crossentropy loss.\n",
    "The model isn't very complex, so this should just take a few minutes even on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "model_2.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 1.4219 - accuracy: 0.4013 - val_loss: 1.2607 - val_accuracy: 0.4952\n",
      "Epoch 2/2\n",
      "487/487 [==============================] - 1s 3ms/step - loss: 1.1755 - accuracy: 0.5700 - val_loss: 1.1259 - val_accuracy: 0.5835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f88e8647e80>"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(X_train_val, y_train_val, batch_size=1024,\n",
    "              epochs=2, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: model_CNN: 0.5840120481927711\n"
     ]
    }
   ],
   "source": [
    "y_predict_2, a_2 = Accuracy(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the best model then ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best model is: model_CNN\n"
     ]
    }
   ],
   "source": [
    "print(\"the best model is: {}\".format(model_1.name if a_1 > a_2 else model_2.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_epochs=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 1.1768 - accuracy: 0.5538 - val_loss: 1.1359 - val_accuracy: 0.5750\n",
      "Epoch 2/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 1.1038 - accuracy: 0.5842 - val_loss: 1.0837 - val_accuracy: 0.5951\n",
      "Epoch 3/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 1.0637 - accuracy: 0.6043 - val_loss: 1.0534 - val_accuracy: 0.6165\n",
      "Epoch 4/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 1.0395 - accuracy: 0.6203 - val_loss: 1.0355 - val_accuracy: 0.6189\n",
      "Epoch 5/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 1.0214 - accuracy: 0.6314 - val_loss: 1.0181 - val_accuracy: 0.6380\n",
      "Epoch 6/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 1.0068 - accuracy: 0.6400 - val_loss: 1.0068 - val_accuracy: 0.6409\n",
      "Epoch 7/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9945 - accuracy: 0.6464 - val_loss: 0.9931 - val_accuracy: 0.6504\n",
      "Epoch 8/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9841 - accuracy: 0.6509 - val_loss: 0.9831 - val_accuracy: 0.6546\n",
      "Epoch 9/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9751 - accuracy: 0.6552 - val_loss: 0.9747 - val_accuracy: 0.6564\n",
      "Epoch 10/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9661 - accuracy: 0.6590 - val_loss: 0.9701 - val_accuracy: 0.6573\n",
      "Epoch 11/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9581 - accuracy: 0.6619 - val_loss: 0.9602 - val_accuracy: 0.6635\n",
      "Epoch 12/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9505 - accuracy: 0.6652 - val_loss: 0.9515 - val_accuracy: 0.6658\n",
      "Epoch 13/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9432 - accuracy: 0.6680 - val_loss: 0.9453 - val_accuracy: 0.6697\n",
      "Epoch 14/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9369 - accuracy: 0.6703 - val_loss: 0.9412 - val_accuracy: 0.6710\n",
      "Epoch 15/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9304 - accuracy: 0.6730 - val_loss: 0.9326 - val_accuracy: 0.6744\n",
      "Epoch 16/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9247 - accuracy: 0.6757 - val_loss: 0.9272 - val_accuracy: 0.6787\n",
      "Epoch 17/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9190 - accuracy: 0.6782 - val_loss: 0.9206 - val_accuracy: 0.6795\n",
      "Epoch 18/40\n",
      "487/487 [==============================] - 1s 2ms/step - loss: 0.9135 - accuracy: 0.6805 - val_loss: 0.9166 - val_accuracy: 0.6808\n"
     ]
    }
   ],
   "source": [
    "history_1 = model_1.fit(X_train_val, y_train_val, batch_size=1024,\n",
    "              epochs=more_epochs, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(X_train_val, y_train_val, batch_size=1024,\n",
    "              epochs=more_epochs, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_1_last, a_1_last = Accuracy(model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_2_last, a_2_last = Accuracy(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History(model_1.name, history_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "History(model_2.name, history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot( history_1.history['val_accuracy'], label = 'Validation Accuracy: model DNN')\n",
    "plt.plot( history_2.history['val_accuracy'], label = 'Validation Accuracy: model CNN')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the conclusion changed ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"the best model is: {}\".format(model_1.name if a_1_last > a_2_last else model_2.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
