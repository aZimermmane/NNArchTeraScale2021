{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "seed = 0\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the jet tagging dataset from Open ML (run this only once, this can take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_openml('hls4ml_lhc_jets_hlf')\n",
    "X, y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "yl = le.fit_transform(y)\n",
    "yc = to_categorical(yl, len(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, yc, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 2\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import setGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def History(label, h):\n",
    "    plt.plot( h.history['loss'], label ='Training Loss: {}'.format(label))\n",
    "    plt.plot( h.history['val_loss'], label = 'Validation Loss: {}'.format(label))\n",
    "    plt.plot( h.history['accuracy'], label = 'Training Accuracy: {}'.format(label))\n",
    "    plt.plot( h.history['val_accuracy'], label = 'Validation Accuracy: {}'.format(label))\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(m, X, Y):\n",
    "    pred = m.predict( X)\n",
    "    a = accuracy_score(np.argmax(Y, axis=1), np.argmax(pred, axis=1))\n",
    "    print(\"Accuracy: {}: {}\".format(m.name, a))\n",
    "    return pred, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a simple dense model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use 3 hidden layers with 32, then 64, then 64 neurons. Each layer will use `relu` activation.\n",
    "Add an output layer with 5 neurons (one for each class), then finish with Softmax activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense, Activation, BatchNormalization, Conv1D, Dropout, Reshape, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Input(shape=(16,))\n",
    "d = Dense(32, name='fc1', activation='relu')(i)\n",
    "d = Dense(64, name='fc2', activation='relu')(d)\n",
    "d = Dense(64, name='fc3', activation='relu')(d)\n",
    "o = Dense(len(le.classes_), activation='softmax', name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001))(d)\n",
    "model = Model(inputs=i, outputs=o, name='model_DNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_DNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16)]              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 7,141\n",
      "Trainable params: 7,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "We'll use Adam optimizer with categorical crossentropy loss.\n",
    "The model isn't very complex, so this should just take a few minutes even on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_folds=10\n",
    "folding = StratifiedKFold(n_splits=n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 1.6280 - accuracy: 0.3728 - val_loss: 1.3246 - val_accuracy: 0.4207\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 1.2855 - accuracy: 0.4519 - val_loss: 1.2397 - val_accuracy: 0.5032\n",
      "Accuracy: model_DNN_0: 0.4980240963855422\n",
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 1.1964 - accuracy: 0.5486 - val_loss: 1.1525 - val_accuracy: 0.5750\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 1.1173 - accuracy: 0.5897 - val_loss: 1.0879 - val_accuracy: 0.6025\n",
      "Accuracy: model_DNN_1: 0.6031566265060241\n",
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 1.0680 - accuracy: 0.6088 - val_loss: 1.0513 - val_accuracy: 0.5944\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 1.0376 - accuracy: 0.6257 - val_loss: 1.0259 - val_accuracy: 0.6274\n",
      "Accuracy: model_DNN_2: 0.6251084337349397\n",
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 1.0168 - accuracy: 0.6392 - val_loss: 1.0062 - val_accuracy: 0.6498\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 1.0004 - accuracy: 0.6493 - val_loss: 0.9947 - val_accuracy: 0.6511\n",
      "Accuracy: model_DNN_3: 0.6504698795180723\n",
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9873 - accuracy: 0.6557 - val_loss: 0.9805 - val_accuracy: 0.6617\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9765 - accuracy: 0.6601 - val_loss: 0.9701 - val_accuracy: 0.6646\n",
      "Accuracy: model_DNN_4: 0.6640843373493975\n",
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9670 - accuracy: 0.6640 - val_loss: 0.9634 - val_accuracy: 0.6645\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9593 - accuracy: 0.6672 - val_loss: 0.9571 - val_accuracy: 0.6709\n",
      "Accuracy: model_DNN_5: 0.6688915662650602\n",
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9519 - accuracy: 0.6694 - val_loss: 0.9489 - val_accuracy: 0.6699\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9455 - accuracy: 0.6718 - val_loss: 0.9439 - val_accuracy: 0.6725\n",
      "Accuracy: model_DNN_6: 0.6700963855421687\n",
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9402 - accuracy: 0.6741 - val_loss: 0.9411 - val_accuracy: 0.6766\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9340 - accuracy: 0.6765 - val_loss: 0.9328 - val_accuracy: 0.6791\n",
      "Accuracy: model_DNN_7: 0.6789638554216868\n",
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9289 - accuracy: 0.6784 - val_loss: 0.9256 - val_accuracy: 0.6807\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9227 - accuracy: 0.6811 - val_loss: 0.9198 - val_accuracy: 0.6840\n",
      "Accuracy: model_DNN_8: 0.683433734939759\n",
      "Epoch 1/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9173 - accuracy: 0.6832 - val_loss: 0.9151 - val_accuracy: 0.6851\n",
      "Epoch 2/2\n",
      "548/548 [==============================] - 1s 2ms/step - loss: 0.9116 - accuracy: 0.6856 - val_loss: 0.9090 - val_accuracy: 0.6859\n",
      "Accuracy: model_DNN_9: 0.6873855421686746\n"
     ]
    }
   ],
   "source": [
    "histories=[]\n",
    "accuracies=[]\n",
    "models=[]\n",
    "for i_fold, (train_index, test_index) in enumerate(folding.split(X, y)):\n",
    "    X_fold_train, X_fold_test = X[train_index], X[test_index]\n",
    "    y_fold_train, y_fold_test = yc[train_index], yc[test_index]\n",
    "    models.append( Model(inputs=i, outputs=o, name='model_DNN_{}'.format(i_fold)) )\n",
    "    models[-1].compile(optimizer=Adam(lr=0.0001), loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    histories.append(models[-1].fit( X_fold_train, y_fold_train, batch_size=1024,\n",
    "                    epochs=2, validation_split=0.25, shuffle=True) )\n",
    "    _, a = Accuracy(models[-1], X_fold_test, y_fold_test)\n",
    "    accuracies.append( a )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model accuracy is 0.643 +/- 0.055 over 10 folds\n"
     ]
    }
   ],
   "source": [
    "print(\"The model accuracy is {:0.3f} +/- {:0.3f} over {} folds\".format(np.mean(accuracies),np.std(accuracies), n_folds ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
